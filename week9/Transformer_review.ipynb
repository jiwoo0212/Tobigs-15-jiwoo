{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 RNN, LSTM, Seq2Seq 모델들은 recurrunt하게 순차적인 학습만 가능하기에 병렬처리를 하는 것에 대한 제약이 존재합니다. \n",
    "transformer는 rnn계열 모델을 전혀 쓰지 않고, 인풋과 아웃풋 사이의 전체적인 연관성을 찾는 attention mechanism만 사용합니다. 이는 병렬처리가 잘 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dladustn95.github.io/assets/images/Transformer_figure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformer는 위의 그림과 같은 구조를 가지고 있습니다. \n",
    "\n",
    "인코더는 임베딩 행렬과 임베딩의 위치 정보를 나타내는 positional encoding이 함께 들어오고, 그 뒤론 Multi-Head attention, Fully connected layer 가 있는 구조입니다.\n",
    "\n",
    "각 레이어에 residual connection과 layer normalization 을 적용합니다.\n",
    "\n",
    "\n",
    "디코더는 Masked Multi-head attention, Multi-head attention, Fully connected layer 3개의 파트로 구성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dladustn95.github.io/assets/images/Transformer_figure2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "#### Scaled Dot-Product Attention, Multi-Head attention\n",
    "\n",
    "attention은 Query, Key, Value로 구성됩니다. 예를 들어 'I love you'에서 'I'와 나머지 단어들과 관계성을 볼 때 query는 'I'이고, key는 'love','you'가 됩니다.\n",
    "\n",
    "Query가 들어오면 Query와 key 간의 weight를 구하고 이를 value에 곱해서 attention value를 얻게 됩니다.\n",
    "\n",
    "Multi-Head attention은 이러한 Scaled Dot-Product Attention를 h개 겹쳐서 각각의 값들을 concat하여 attention value를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder의 Multi-head attention\n",
    "\n",
    "인코더와 디코더에서 모두 사용되며, 인풋으로 주어진 문장안에서 단어간의 연관성을 계산합니다. 이는 seq2seq에서의 context vector를 대체합니다.\n",
    "\n",
    "### Masked multi-head attention\n",
    "\n",
    "디코더에만 존재하는 attention으로, 마스크를 사용하여 정보의 전달이 앞에서 뒤로 흘러갈 수 있도록 합니다. \n",
    "\n",
    "### Decoder의 Multi-head attention\n",
    "\n",
    "Query로 Decoder의 이전 Layer output값이  Key, Value로는 Encoder output layer의 값이 사용됩니다. \n",
    "예를 들어 'I am a teacher' 라는 문장을 한국어로 번역한다고 할 때 '선생님'이라는 단어와 앞서 단어들과의 연관성을 보는 경우를 생각할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feed-Forward Networks\n",
    "인코더와 디코더의 fully connected layer에서 두번의 선형 변환(중간에 ReLU함수 사용)을 합니다.\n",
    "\n",
    "### Embeddings and Softmax\n",
    "미리 학습된 임베딩을 사용하였고, 두 embedding layer와 softmax 이전의 linear transformation에서 동일한 weight 행렬을 공유합니다.\n",
    "\n",
    "### Positional Encoding\n",
    "기존 임베딩 방식은 단어의 순서를 나타낼 수 없기 때문에 Positional Encoding을 통해 순서성을 부여합니다. 임베딩 차원과 동일한 차원으로 설정하여 더해질 수 있게 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Attention의 이점\n",
    "Self Attention의 이점으로는 \n",
    "1. layer의 계산 복잡도가 감소한다. 2. 더 많은 양을 병렬 처리할 수 있다. 3. 긴 거리의 dependency를 잘 학습할 수 있다. 4. 더 해석 가능한 모델을 만든다. 등이 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "standard WMT 2014 English-German dataset 을 사용했습니다. 4.5 million개의 문장쌍을 가진다고 합니다. \n",
    "\n",
    "### Optimizer\n",
    "Adam optimizer를 사용했습니다.\n",
    "\n",
    "### Regularization\n",
    "Residual Dropout, Label Smoothing을 사용했습니다.\n",
    "\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "#### 보다 적은 training cost로 SOTA달성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://heiwais25.github.io/img/nlp/arxiv1706_img4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter 조정에 따른 성능, 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://heiwais25.github.io/img/nlp/arxiv1706_img5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 자료: https://www.youtube.com/watch?v=AA621UofTUA\n",
    "\n",
    "https://heiwais25.github.io/nlp/2019/08/05/Attention-Is-All-You-Need/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
